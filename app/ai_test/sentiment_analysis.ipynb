{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 6.3/10.0 MB 32.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 29.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 8.4/12.6 MB 40.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 34.3 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 12.3 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 numpy-2.1.3 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.4.5 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.2 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Dev\\private\\ai_python\\venv\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Dev\\private\\ai_python\\venv\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Collecting setuptools (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading setuptools-75.5.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp312-cp312-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wheel-0.45.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\dev\\private\\ai_python\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 7.1/390.3 MB 33.6 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 15.7/390.3 MB 36.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 24.4/390.3 MB 37.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 29.4/390.3 MB 34.5 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 37.2/390.3 MB 34.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 45.6/390.3 MB 35.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 54.5/390.3 MB 36.6 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 62.9/390.3 MB 36.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 71.3/390.3 MB 37.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 80.0/390.3 MB 37.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 88.6/390.3 MB 37.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 97.0/390.3 MB 37.7 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 104.6/390.3 MB 37.7 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 112.7/390.3 MB 37.7 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 121.4/390.3 MB 37.8 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 130.0/390.3 MB 37.9 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 138.4/390.3 MB 38.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 146.8/390.3 MB 38.1 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 155.2/390.3 MB 38.3 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 163.1/390.3 MB 38.2 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 169.3/390.3 MB 37.7 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 176.2/390.3 MB 37.4 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 183.0/390.3 MB 37.2 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 189.8/390.3 MB 37.0 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 196.6/390.3 MB 36.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 202.9/390.3 MB 36.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 211.0/390.3 MB 36.6 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 219.7/390.3 MB 36.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 226.5/390.3 MB 36.5 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 235.1/390.3 MB 36.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 243.5/390.3 MB 36.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 251.9/390.3 MB 36.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 256.6/390.3 MB 36.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 265.3/390.3 MB 36.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 273.7/390.3 MB 36.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 282.1/390.3 MB 36.6 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 290.7/390.3 MB 37.0 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 298.8/390.3 MB 37.1 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 307.8/390.3 MB 37.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 316.4/390.3 MB 37.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 325.1/390.3 MB 37.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 333.4/390.3 MB 37.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 335.0/390.3 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 342.9/390.3 MB 36.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 351.3/390.3 MB 36.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 352.8/390.3 MB 35.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.7/390.3 MB 35.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 368.3/390.3 MB 35.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 375.1/390.3 MB 35.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.8/390.3 MB 35.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 35.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 35.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 35.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 32.3 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   -------------------------------------- - 7.6/7.8 MB 42.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 34.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 7.6/11.0 MB 36.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 7.1/15.6 MB 33.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.6 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 28.9 MB/s eta 0:00:00\n",
      "Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 24.5 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 5.2/44.5 MB 24.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.5/44.5 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.4/44.5 MB 21.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.0/44.5 MB 25.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.7/44.5 MB 28.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.7/44.5 MB 30.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.4/44.5 MB 27.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 26.5 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 26.3 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 29.1 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 19.8 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 25.8 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.5.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 20.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.0-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, tzdata, threadpoolctl, termcolor, tensorboard-data-server, setuptools, pyparsing, protobuf, pillow, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, joblib, grpcio, google-pasta, gast, fonttools, cycler, absl-py, werkzeug, scipy, pandas, ml-dtypes, markdown-it-py, h5py, contourpy, astunparse, tensorboard, scikit-learn, rich, matplotlib, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 contourpy-1.3.1 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.55.0 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 joblib-1.4.2 keras-3.6.0 kiwisolver-1.4.7 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.9.2 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 pandas-2.2.3 pillow-11.0.0 protobuf-5.28.3 pyparsing-3.2.0 pytz-2024.2 rich-13.9.4 scikit-learn-1.5.2 scipy-1.14.1 setuptools-75.5.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2024.2 werkzeug-3.1.3 wheel-0.45.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas tensorflow matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\private\\ai_python\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Dev\\private\\ai_python\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('finance_data.csv', <http.client.HTTPMessage at 0x27600545280>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\", filename=\"finance_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 4846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('finance_data.csv')\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "      <td>런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Rinkuskiai's beer sales fell by 6.5 per cent t...</td>\n",
       "      <td>린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "      <td>영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "      <td>페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "      <td>핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels                                           sentence  \\\n",
       "0      neutral  According to Gran, the company has no plans to...   \n",
       "1      neutral  Technopolis plans to develop in stages an area...   \n",
       "2     negative  The international electronic industry company ...   \n",
       "3     positive  With the new production plant the company woul...   \n",
       "4     positive  According to the company's updated strategy fo...   \n",
       "...        ...                                                ...   \n",
       "4841  negative  LONDON MarketWatch -- Share prices ended lower...   \n",
       "4842   neutral  Rinkuskiai's beer sales fell by 6.5 per cent t...   \n",
       "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...   \n",
       "4844  negative  Net sales of the Paper segment decreased to EU...   \n",
       "4845  negative  Sales in Finland decreased by 10.5 % in Januar...   \n",
       "\n",
       "                                           kor_sentence  \n",
       "0     Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
       "1     테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
       "2     국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
       "3     새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
       "4     2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  \n",
       "...                                                 ...  \n",
       "4841  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...  \n",
       "4842  린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...  \n",
       "4843  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...  \n",
       "4844  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...  \n",
       "4845   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.  \n",
       "\n",
       "[4846 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Com\\AppData\\Local\\Temp\\ipykernel_10268\\2806054088.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['labels'] = data['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           sentence  \\\n",
       "0       0  According to Gran, the company has no plans to...   \n",
       "1       0  Technopolis plans to develop in stages an area...   \n",
       "2       2  The international electronic industry company ...   \n",
       "3       1  With the new production plant the company woul...   \n",
       "4       1  According to the company's updated strategy fo...   \n",
       "\n",
       "                                        kor_sentence  \n",
       "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
       "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
       "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
       "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
       "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'] = data['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                       kor_sentence\n",
       "0       0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...\n",
       "1       0  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...\n",
       "2       2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...\n",
       "3       1  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...\n",
       "4       1  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4846 entries, 0 to 4845\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   labels        4846 non-null   int64 \n",
      " 1   kor_sentence  4846 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 75.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 여부 : False\n"
     ]
    }
   ],
   "source": [
    "print('결측값 여부 :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence 열의 유니크한 값 : 4827\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence 열의 유니크한 값 :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0</td>\n",
       "      <td>이 발표 내용에 대한 책임은 전적으로 발행자에게 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>0</td>\n",
       "      <td>핀란드 헬싱키에 본사를 둔 레민카이넨 그룹은 토목 공학, 건축 계약, 기술 건축 서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>0</td>\n",
       "      <td>이 보고서는 블랙 앤 데커, 피스카스, 피스카스 브랜드, 후스크바르나 아웃도어 프로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>0</td>\n",
       "      <td>알스트롬의 주가는 나스닥 OMX 헬싱키에서 인용되고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>0</td>\n",
       "      <td>SSH 통신 보안 코퍼레이션은 핀란드 헬싱키에 본사를 두고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>0</td>\n",
       "      <td>재정적인 세부사항은 공개되지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>0</td>\n",
       "      <td>재정적인 세부사항은 공개되지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>0</td>\n",
       "      <td>금융 조건은 공개되지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>0</td>\n",
       "      <td>재정적인 세부사항은 제공되지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>0</td>\n",
       "      <td>재정적인 세부사항은 공개되지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>0</td>\n",
       "      <td>Proha Plc (Euronext :7327)는 오늘 (5월 19일) 완전 소유 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>0</td>\n",
       "      <td>공정 및 자원, 산업기계, 건축, 건축, 건설, 전기, 운송, 전자, 화학, 석유화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>0</td>\n",
       "      <td>판매 가격은 공개되지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0</td>\n",
       "      <td>아스포의 그룹 구조와 비즈니스 운영은 미리 정의된 일정 없이 지속적으로 개발됩니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>0</td>\n",
       "      <td>2007년에 에트플랜은 125.2m의 회전율을 기록했다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>0</td>\n",
       "      <td>그 거래의 가치는 공개되지 않았다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "1099       0                   이 발표 내용에 대한 책임은 전적으로 발행자에게 있습니다.\n",
       "1394       0  핀란드 헬싱키에 본사를 둔 레민카이넨 그룹은 토목 공학, 건축 계약, 기술 건축 서...\n",
       "1416       0  이 보고서는 블랙 앤 데커, 피스카스, 피스카스 브랜드, 후스크바르나 아웃도어 프로...\n",
       "2396       0                   알스트롬의 주가는 나스닥 OMX 헬싱키에서 인용되고 있다.\n",
       "2567       0               SSH 통신 보안 코퍼레이션은 핀란드 헬싱키에 본사를 두고 있다.\n",
       "2889       0                               재정적인 세부사항은 공개되지 않았다.\n",
       "2890       0                               재정적인 세부사항은 공개되지 않았다.\n",
       "2892       0                                   금융 조건은 공개되지 않았다.\n",
       "3050       0                               재정적인 세부사항은 제공되지 않았다.\n",
       "3051       0                               재정적인 세부사항은 공개되지 않았다.\n",
       "3094       0  Proha Plc (Euronext :7327)는 오늘 (5월 19일) 완전 소유 ...\n",
       "3206       0  공정 및 자원, 산업기계, 건축, 건축, 건설, 전기, 운송, 전자, 화학, 석유화...\n",
       "3350       0                                   판매 가격은 공개되지 않았다.\n",
       "3538       0     아스포의 그룹 구조와 비즈니스 운영은 미리 정의된 일정 없이 지속적으로 개발됩니다.\n",
       "3617       0                    2007년에 에트플랜은 125.2m의 회전율을 기록했다.\n",
       "3938       0                                그 거래의 가치는 공개되지 않았다."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 4827\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거\n",
    "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='labels'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGwCAYAAAC3qV8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlnUlEQVR4nO3de3BU5cHH8V8I7BIuu2kIySZDgigViAJCtGSrxAtpAkaUMbaiKFgRiiZWiGKaKY0UOg3FC4pyaWtptEJFW6FCFAxBQCQIpBMuQeINJji4iYrZhRSSQPb9o5PzuiWggYTNA9/PzJlh93n27HPadfKds2d3Q/x+v18AAAAG6RDsBQAAALQUAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACM06KAWbRokQYNGiSHwyGHwyG32623337bGj9+/LgyMzPVo0cPdevWTRkZGaqqqgrYR2VlpdLT09WlSxdFRUVp+vTpOnHiRMCcDRs2aOjQobLb7erbt68KCgrO/ggBAMAFp0UB06tXL82ZM0elpaXasWOHbrrpJt12220qLy+XJE2bNk2rVq3S66+/ro0bN+rQoUO6/fbbrcefPHlS6enpqq+v15YtW/TSSy+poKBAeXl51pz9+/crPT1dN954o8rKyjR16lQ98MADWrt2bSsdMgAAMF3Iuf6YY0REhJ588kndcccd6tmzp5YtW6Y77rhDkrRv3z4NGDBAJSUlSkpK0ttvv61bbrlFhw4dUnR0tCRp8eLFysnJ0ZdffimbzaacnBwVFhZqz5491nOMHTtWNTU1WrNmzfdeV2Njow4dOqTu3bsrJCTkXA4RAACcJ36/X0eOHFFsbKw6dDjDeRb/WTpx4oT/73//u99ms/nLy8v9xcXFfkn+b775JmBefHy8/5lnnvH7/X7/b37zG//gwYMDxj/77DO/JP+///1vv9/v9w8fPtz/yCOPBMxZsmSJ3+FwnHE9x48f93u9Xmvbu3evXxIbGxsbGxubgdvBgwfP+He/o1po9+7dcrvdOn78uLp166YVK1YoISFBZWVlstlsCg8PD5gfHR0tj8cjSfJ4PNaZl2+PN42daY7P59OxY8cUFhbW7Lry8/P129/+9pT7Dx48KIfD0dLDBAAAQeDz+RQXF6fu3bufcV6LA6Zfv34qKyuT1+vVP/7xD02YMEEbN24864W2ltzcXGVnZ1u3m/4HaLrgGAAAmOO7Lv9occDYbDb17dtXkpSYmKjt27frueee05133qn6+nrV1NQEnIWpqqqSy+WSJLlcLm3bti1gf02fUvr2nP/95FJVVZUcDsdpz75Ikt1ul91ub+nhAAAAA53z98A0Njaqrq5OiYmJ6tSpk4qLi62xiooKVVZWyu12S5Lcbrd2796t6upqa05RUZEcDocSEhKsOd/eR9Ocpn0AAAC06AxMbm6uRo0apfj4eB05ckTLli3Thg0btHbtWjmdTk2cOFHZ2dmKiIiQw+HQww8/LLfbraSkJElSamqqEhISdO+992ru3LnyeDyaMWOGMjMzrbMnU6ZM0QsvvKDHH39c999/v9avX6/XXntNhYWFrX/0AADASC0KmOrqao0fP15ffPGFnE6nBg0apLVr1+onP/mJJGnevHnq0KGDMjIyVFdXp7S0NC1cuNB6fGhoqFavXq0HH3xQbrdbXbt21YQJEzRr1ixrTp8+fVRYWKhp06bpueeeU69evfTiiy8qLS2tlQ4ZAACY7py/B6a98vl8cjqd8nq9XMQLAIAhvu/fb34LCQAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMZp0W8hofVd8it+pLK1HJiTHuwlAADOE87AAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACM06KAyc/P1zXXXKPu3bsrKipKY8aMUUVFRcCcG264QSEhIQHblClTAuZUVlYqPT1dXbp0UVRUlKZPn64TJ04EzNmwYYOGDh0qu92uvn37qqCg4OyOEAAAXHBaFDAbN25UZmamtm7dqqKiIjU0NCg1NVW1tbUB8yZNmqQvvvjC2ubOnWuNnTx5Uunp6aqvr9eWLVv00ksvqaCgQHl5edac/fv3Kz09XTfeeKPKyso0depUPfDAA1q7du05Hi4AALgQdGzJ5DVr1gTcLigoUFRUlEpLS5WcnGzd36VLF7lcrmb38c4772jv3r1at26doqOjddVVV2n27NnKycnRzJkzZbPZtHjxYvXp00dPP/20JGnAgAHavHmz5s2bp7S0tGb3W1dXp7q6Ouu2z+dryaEBAACDnNM1MF6vV5IUERERcP/SpUsVGRmpK6+8Urm5ufrPf/5jjZWUlGjgwIGKjo627ktLS5PP51N5ebk1JyUlJWCfaWlpKikpOe1a8vPz5XQ6rS0uLu5cDg0AALRjLToD822NjY2aOnWqrr32Wl155ZXW/Xfffbd69+6t2NhY7dq1Szk5OaqoqNAbb7whSfJ4PAHxIsm67fF4zjjH5/Pp2LFjCgsLO2U9ubm5ys7Otm77fD4iBgCAC9RZB0xmZqb27NmjzZs3B9w/efJk698DBw5UTEyMRowYoU8//VSXXXbZ2a/0O9jtdtnt9jbbPwAAaD/O6i2krKwsrV69Wu+++6569ep1xrnDhg2TJH3yySeSJJfLpaqqqoA5Tbebrps53RyHw9Hs2RcAAHBxaVHA+P1+ZWVlacWKFVq/fr369OnznY8pKyuTJMXExEiS3G63du/ererqamtOUVGRHA6HEhISrDnFxcUB+ykqKpLb7W7JcgEAwAWqRQGTmZmpV155RcuWLVP37t3l8Xjk8Xh07NgxSdKnn36q2bNnq7S0VAcOHNCbb76p8ePHKzk5WYMGDZIkpaamKiEhQffee6927typtWvXasaMGcrMzLTeApoyZYo+++wzPf7449q3b58WLlyo1157TdOmTWvlwwcAACZqUcAsWrRIXq9XN9xwg2JiYqxt+fLlkiSbzaZ169YpNTVV/fv316OPPqqMjAytWrXK2kdoaKhWr16t0NBQud1u3XPPPRo/frxmzZplzenTp48KCwtVVFSkwYMH6+mnn9aLL7542o9QAwCAi0uI3+/3B3sRbcHn88npdMrr9crhcAR7Oad1ya8Kg72EC8aBOenBXgIA4Bx937/f/BYSAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACM06KAyc/P1zXXXKPu3bsrKipKY8aMUUVFRcCc48ePKzMzUz169FC3bt2UkZGhqqqqgDmVlZVKT09Xly5dFBUVpenTp+vEiRMBczZs2KChQ4fKbrerb9++KigoOLsjBAAAF5wWBczGjRuVmZmprVu3qqioSA0NDUpNTVVtba01Z9q0aVq1apVef/11bdy4UYcOHdLtt99ujZ88eVLp6emqr6/Xli1b9NJLL6mgoEB5eXnWnP379ys9PV033nijysrKNHXqVD3wwANau3ZtKxwyAAAwXYjf7/ef7YO//PJLRUVFaePGjUpOTpbX61XPnj21bNky3XHHHZKkffv2acCAASopKVFSUpLefvtt3XLLLTp06JCio6MlSYsXL1ZOTo6+/PJL2Ww25eTkqLCwUHv27LGea+zYsaqpqdGaNWu+19p8Pp+cTqe8Xq8cDsfZHmKbu+RXhcFewgXjwJz0YC8BAHCOvu/f73O6Bsbr9UqSIiIiJEmlpaVqaGhQSkqKNad///6Kj49XSUmJJKmkpEQDBw604kWS0tLS5PP5VF5ebs359j6a5jTtozl1dXXy+XwBGwAAuDCddcA0NjZq6tSpuvbaa3XllVdKkjwej2w2m8LDwwPmRkdHy+PxWHO+HS9N401jZ5rj8/l07NixZteTn58vp9NpbXFxcWd7aAAAoJ0764DJzMzUnj179Oqrr7bmes5abm6uvF6vtR08eDDYSwIAAG2k49k8KCsrS6tXr9amTZvUq1cv636Xy6X6+nrV1NQEnIWpqqqSy+Wy5mzbti1gf02fUvr2nP/95FJVVZUcDofCwsKaXZPdbpfdbj+bwwEAAIZp0RkYv9+vrKwsrVixQuvXr1efPn0CxhMTE9WpUycVFxdb91VUVKiyslJut1uS5Ha7tXv3blVXV1tzioqK5HA4lJCQYM359j6a5jTtAwAAXNxadAYmMzNTy5Yt07/+9S91797dumbF6XQqLCxMTqdTEydOVHZ2tiIiIuRwOPTwww/L7XYrKSlJkpSamqqEhATde++9mjt3rjwej2bMmKHMzEzrDMqUKVP0wgsv6PHHH9f999+v9evX67XXXlNhIZ/YAQAALTwDs2jRInm9Xt1www2KiYmxtuXLl1tz5s2bp1tuuUUZGRlKTk6Wy+XSG2+8YY2HhoZq9erVCg0Nldvt1j333KPx48dr1qxZ1pw+ffqosLBQRUVFGjx4sJ5++mm9+OKLSktLa4VDBgAApjun74Fpz/gemIsP3wMDAOY7L98DAwAAEAwEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjNPigNm0aZNGjx6t2NhYhYSEaOXKlQHj9913n0JCQgK2kSNHBsw5fPiwxo0bJ4fDofDwcE2cOFFHjx4NmLNr1y4NHz5cnTt3VlxcnObOndvyowMAABekFgdMbW2tBg8erAULFpx2zsiRI/XFF19Y29///veA8XHjxqm8vFxFRUVavXq1Nm3apMmTJ1vjPp9Pqamp6t27t0pLS/Xkk09q5syZ+tOf/tTS5QIAgAtQx5Y+YNSoURo1atQZ59jtdrlcrmbHPvzwQ61Zs0bbt2/X1VdfLUl6/vnndfPNN+upp55SbGysli5dqvr6ei1ZskQ2m01XXHGFysrK9MwzzwSEzrfV1dWprq7Ouu3z+Vp6aAAAwBBtcg3Mhg0bFBUVpX79+unBBx/U119/bY2VlJQoPDzcihdJSklJUYcOHfTBBx9Yc5KTk2Wz2aw5aWlpqqio0DfffNPsc+bn58vpdFpbXFxcWxwaAABoB1o9YEaOHKmXX35ZxcXF+sMf/qCNGzdq1KhROnnypCTJ4/EoKioq4DEdO3ZURESEPB6PNSc6OjpgTtPtpjn/Kzc3V16v19oOHjzY2ocGAADaiRa/hfRdxo4da/174MCBGjRokC677DJt2LBBI0aMaO2ns9jtdtnt9jbbPwAAaD/a/GPUl156qSIjI/XJJ59Iklwul6qrqwPmnDhxQocPH7aum3G5XKqqqgqY03T7dNfWAACAi0ebB8znn3+ur7/+WjExMZIkt9utmpoalZaWWnPWr1+vxsZGDRs2zJqzadMmNTQ0WHOKiorUr18//eAHP2jrJQMAgHauxQFz9OhRlZWVqaysTJK0f/9+lZWVqbKyUkePHtX06dO1detWHThwQMXFxbrtttvUt29fpaWlSZIGDBigkSNHatKkSdq2bZvef/99ZWVlaezYsYqNjZUk3X333bLZbJo4caLKy8u1fPlyPffcc8rOzm69IwcAAMZqccDs2LFDQ4YM0ZAhQyRJ2dnZGjJkiPLy8hQaGqpdu3bp1ltv1eWXX66JEycqMTFR7733XsD1KUuXLlX//v01YsQI3XzzzbruuusCvuPF6XTqnXfe0f79+5WYmKhHH31UeXl5p/0INQAAuLiE+P1+f7AX0RZ8Pp+cTqe8Xq8cDkewl3Nal/yqMNhLuGAcmJMe7CUAAM7R9/37zW8hAQAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAON0DPYCALQ/fEN06+DboYG2wxkYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxWhwwmzZt0ujRoxUbG6uQkBCtXLkyYNzv9ysvL08xMTEKCwtTSkqKPv7444A5hw8f1rhx4+RwOBQeHq6JEyfq6NGjAXN27dql4cOHq3PnzoqLi9PcuXNbfnQAAOCC1OKAqa2t1eDBg7VgwYJmx+fOnav58+dr8eLF+uCDD9S1a1elpaXp+PHj1pxx48apvLxcRUVFWr16tTZt2qTJkydb4z6fT6mpqerdu7dKS0v15JNPaubMmfrTn/50FocIAAAuNB1b+oBRo0Zp1KhRzY75/X49++yzmjFjhm677TZJ0ssvv6zo6GitXLlSY8eO1Ycffqg1a9Zo+/btuvrqqyVJzz//vG6++WY99dRTio2N1dKlS1VfX68lS5bIZrPpiiuuUFlZmZ555pmA0AEAABenVr0GZv/+/fJ4PEpJSbHuczqdGjZsmEpKSiRJJSUlCg8Pt+JFklJSUtShQwd98MEH1pzk5GTZbDZrTlpamioqKvTNN980+9x1dXXy+XwBGwAAuDC1asB4PB5JUnR0dMD90dHR1pjH41FUVFTAeMeOHRUREREwp7l9fPs5/ld+fr6cTqe1xcXFnfsBAQCAdumC+RRSbm6uvF6vtR08eDDYSwIAAG2kVQPG5XJJkqqqqgLur6qqssZcLpeqq6sDxk+cOKHDhw8HzGluH99+jv9lt9vlcDgCNgAAcGFq1YDp06ePXC6XiouLrft8Pp8++OADud1uSZLb7VZNTY1KS0utOevXr1djY6OGDRtmzdm0aZMaGhqsOUVFRerXr59+8IMftOaSAQCAgVocMEePHlVZWZnKysok/ffC3bKyMlVWViokJERTp07V7373O7355pvavXu3xo8fr9jYWI0ZM0aSNGDAAI0cOVKTJk3Stm3b9P777ysrK0tjx45VbGysJOnuu++WzWbTxIkTVV5eruXLl+u5555TdnZ2qx04AAAwV4s/Rr1jxw7deOON1u2mqJgwYYIKCgr0+OOPq7a2VpMnT1ZNTY2uu+46rVmzRp07d7Yes3TpUmVlZWnEiBHq0KGDMjIyNH/+fGvc6XTqnXfeUWZmphITExUZGam8vDw+Qg0AACRJIX6/3x/sRbQFn88np9Mpr9fbrq+HueRXhcFewgXjwJz0YC/hgsHrsnXwmgRa7vv+/b5gPoUEAAAuHgQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADBOx2AvAACA73LJrwqDvYQLxoE56cFeQqvgDAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOK0eMDNnzlRISEjA1r9/f2v8+PHjyszMVI8ePdStWzdlZGSoqqoqYB+VlZVKT09Xly5dFBUVpenTp+vEiROtvVQAAGCoNvkm3iuuuELr1q37/yfp+P9PM23aNBUWFur111+X0+lUVlaWbr/9dr3//vuSpJMnTyo9PV0ul0tbtmzRF198ofHjx6tTp076/e9/3xbLBQAAhmmTgOnYsaNcLtcp93u9Xv3lL3/RsmXLdNNNN0mS/vrXv2rAgAHaunWrkpKS9M4772jv3r1at26doqOjddVVV2n27NnKycnRzJkzZbPZmn3Ouro61dXVWbd9Pl9bHBoAAGgH2uQamI8//lixsbG69NJLNW7cOFVWVkqSSktL1dDQoJSUFGtu//79FR8fr5KSEklSSUmJBg4cqOjoaGtOWlqafD6fysvLT/uc+fn5cjqd1hYXF9cWhwYAANqBVg+YYcOGqaCgQGvWrNGiRYu0f/9+DR8+XEeOHJHH45HNZlN4eHjAY6Kjo+XxeCRJHo8nIF6axpvGTic3N1der9faDh482LoHBgAA2o1Wfwtp1KhR1r8HDRqkYcOGqXfv3nrttdcUFhbW2k9nsdvtstvtbbZ/AADQfrT5x6jDw8N1+eWX65NPPpHL5VJ9fb1qamoC5lRVVVnXzLhcrlM+ldR0u7nragAAwMWnzQPm6NGj+vTTTxUTE6PExER16tRJxcXF1nhFRYUqKyvldrslSW63W7t371Z1dbU1p6ioSA6HQwkJCW29XAAAYIBWfwvpscce0+jRo9W7d28dOnRITzzxhEJDQ3XXXXfJ6XRq4sSJys7OVkREhBwOhx5++GG53W4lJSVJklJTU5WQkKB7771Xc+fOlcfj0YwZM5SZmclbRAAAQFIbBMznn3+uu+66S19//bV69uyp6667Tlu3blXPnj0lSfPmzVOHDh2UkZGhuro6paWlaeHChdbjQ0NDtXr1aj344INyu93q2rWrJkyYoFmzZrX2UgEAgKFaPWBeffXVM4537txZCxYs0IIFC047p3fv3nrrrbdae2kAAOACwW8hAQAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOO06YBYsWKBLLrlEnTt31rBhw7Rt27ZgLwkAALQD7TZgli9fruzsbD3xxBP697//rcGDBystLU3V1dXBXhoAAAiydhswzzzzjCZNmqSf//znSkhI0OLFi9WlSxctWbIk2EsDAABB1jHYC2hOfX29SktLlZuba93XoUMHpaSkqKSkpNnH1NXVqa6uzrrt9XolST6fr20Xe44a6/4T7CVcMNr7/9cm4XXZOnhNth5ek62nvb8um9bn9/vPOK9dBsxXX32lkydPKjo6OuD+6Oho7du3r9nH5Ofn67e//e0p98fFxbXJGtH+OJ8N9gqAQLwm0R6Z8ro8cuSInE7nacfbZcCcjdzcXGVnZ1u3GxsbdfjwYfXo0UMhISFBXJn5fD6f4uLidPDgQTkcjmAvB+A1iXaH12Tr8fv9OnLkiGJjY884r10GTGRkpEJDQ1VVVRVwf1VVlVwuV7OPsdvtstvtAfeFh4e31RIvSg6Hg/8w0a7wmkR7w2uydZzpzEuTdnkRr81mU2JiooqLi637GhsbVVxcLLfbHcSVAQCA9qBdnoGRpOzsbE2YMEFXX321fvSjH+nZZ59VbW2tfv7znwd7aQAAIMjabcDceeed+vLLL5WXlyePx6OrrrpKa9asOeXCXrQ9u92uJ5544pS36IBg4TWJ9obX5PkX4v+uzykBAAC0M+3yGhgAAIAzIWAAAIBxCBgAAGAcAgYAABiHgAEAAMZptx+jRnB89dVXWrJkiUpKSuTxeCRJLpdLP/7xj3XfffepZ8+eQV4hAACcgcG3bN++XZdffrnmz58vp9Op5ORkJScny+l0av78+erfv7927NgR7GUCAQ4ePKj7778/2MvARebYsWPavHmz9u7de8rY8ePH9fLLLwdhVRcXvgcGlqSkJA0ePFiLFy8+5Qcw/X6/pkyZol27dqmkpCRIKwROtXPnTg0dOlQnT54M9lJwkfjoo4+UmpqqyspKhYSE6LrrrtOrr76qmJgYSf/93b7Y2Fhek22Mt5Bg2blzpwoKCpr99e6QkBBNmzZNQ4YMCcLKcDF78803zzj+2WefnaeVAP+Vk5OjK6+8Ujt27FBNTY2mTp2qa6+9Vhs2bFB8fHywl3fRIGBgcblc2rZtm/r379/s+LZt2/gpB5x3Y8aMUUhIiM50sri56AbaypYtW7Ru3TpFRkYqMjJSq1at0kMPPaThw4fr3XffVdeuXYO9xIsCAQPLY489psmTJ6u0tFQjRoywYqWqqkrFxcX685//rKeeeirIq8TFJiYmRgsXLtRtt93W7HhZWZkSExPP86pwMTt27Jg6dvz/P58hISFatGiRsrKydP3112vZsmVBXN3Fg4CBJTMzU5GRkZo3b54WLlxovX8bGhqqxMREFRQU6Gc/+1mQV4mLTWJiokpLS08bMN91dgZobU0faBgwYEDA/S+88IIk6dZbbw3Gsi46XMSLZjU0NOirr76SJEVGRqpTp05BXhEuVu+9955qa2s1cuTIZsdra2u1Y8cOXX/99ed5ZbhY5efn67333tNbb73V7PhDDz2kxYsXq7Gx8Tyv7OJCwAAAAOPwPTAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMADOmxtuuEFTp079XnM3bNigkJAQ1dTUnNNzXnLJJXr22WfPaR8A2h8CBgAAGIeAAQAAxiFgAATF3/72N1199dXq3r27XC6X7r77blVXV58y7/3339egQYPUuXNnJSUlac+ePQHjmzdv1vDhwxUWFqa4uDj98pe/VG1tbbPP6ff7NXPmTMXHx8tutys2Nla//OUv2+T4ALQtAgZAUDQ0NGj27NnauXOnVq5cqQMHDui+++47Zd706dP19NNPa/v27erZs6dGjx6thoYGSdKnn36qkSNHKiMjQ7t27dLy5cu1efNmZWVlNfuc//znPzVv3jz98Y9/1Mcff6yVK1dq4MCBbXmYANoIv4UEICjuv/9+69+XXnqp5s+fr2uuuUZHjx5Vt27drLEnnnhCP/nJTyRJL730knr16qUVK1boZz/7mfLz8zVu3DjrwuAf/vCHmj9/vq6//notWrRInTt3DnjOyspKuVwupaSkqFOnToqPj9ePfvSjtj9YAK2OMzAAgqK0tFSjR49WfHy8unfvbv2WUWVlZcA8t9tt/TsiIkL9+vXThx9+KEnauXOnCgoK1K1bN2tLS0tTY2Oj9u/ff8pz/vSnP9WxY8d06aWXatKkSVqxYoVOnDjRhkcJoK0QMADOu9raWqWlpcnhcGjp0qXavn27VqxYIUmqr6//3vs5evSofvGLX6isrMzadu7cqY8//liXXXbZKfPj4uJUUVGhhQsXKiwsTA899JCSk5Ott6QAmIO3kACcd/v27dPXX3+tOXPmKC4uTpK0Y8eOZudu3bpV8fHxkqRvvvlGH330kQYMGCBJGjp0qPbu3au+fft+7+cOCwvT6NGjNXr0aGVmZqp///7avXu3hg4deo5HBeB8ImAAnHfx8fGy2Wx6/vnnNWXKFO3Zs0ezZ89udu6sWbPUo0cPRUdH69e//rUiIyM1ZswYSVJOTo6SkpKUlZWlBx54QF27dtXevXtVVFSkF1544ZR9FRQU6OTJkxo2bJi6dOmiV155RWFhYerdu3dbHi6ANsBbSADOu549e6qgoECvv/66EhISNGfOHD311FPNzp0zZ44eeeQRJSYmyuPxaNWqVbLZbJKkQYMGaePGjfroo480fPhwDRkyRHl5eYqNjW12X+Hh4frzn/+sa6+9VoMGDdK6deu0atUq9ejRo82OFUDbCPH7/f5gLwIAAKAlOAMDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOP8HvLnn2y4o9lsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블의 분포\n",
      "   labels  count\n",
      "0       0   2861\n",
      "1       1   1362\n",
      "2       2    604\n"
     ]
    }
   ],
   "source": [
    "print('레이블의 분포')\n",
    "print(data.groupby('labels').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중립의 비율 = 59.271%\n",
      "긍정의 비율 = 28.216%\n",
      "부정의 비율 = 12.513%\n"
     ]
    }
   ],
   "source": [
    "print(f'중립의 비율 = {round(data[\"labels\"].value_counts()[0]/len(data) * 100,3)}%')\n",
    "print(f'긍정의 비율 = {round(data[\"labels\"].value_counts()[1]/len(data) * 100,3)}%')\n",
    "print(f'부정의 비율 = {round(data[\"labels\"].value_counts()[2]/len(data) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>2</td>\n",
       "      <td>런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>0</td>\n",
       "      <td>린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>2</td>\n",
       "      <td>영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>2</td>\n",
       "      <td>페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>2</td>\n",
       "      <td>핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...\n",
       "1          0  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...\n",
       "2          2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...\n",
       "3          1  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...\n",
       "4          1  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...\n",
       "...      ...                                                ...\n",
       "4841       2  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...\n",
       "4842       0  린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...\n",
       "4843       2  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...\n",
       "4844       2  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...\n",
       "4845       2   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.\n",
       "\n",
       "[4827 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문의 개수: 4827\n",
      "레이블의 개수: 4827\n"
     ]
    }
   ],
   "source": [
    "X_data = data['kor_sentence']\n",
    "y_data = data['labels']\n",
    "print('본문의 개수: {}'.format(len(X_data)))\n",
    "print('레이블의 개수: {}'.format(len(y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 3861\n",
      "테스트 샘플의 개수 : 966\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 :', len(X_train))\n",
    "print('테스트 샘플의 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------훈련 데이터의 비율-----------\n",
      "중립 = 59.285%\n",
      "긍정 = 28.205%\n",
      "부정 = 12.51%\n"
     ]
    }
   ],
   "source": [
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'중립 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
    "print(f'긍정 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
    "print(f'부정 = {round(y_train.value_counts()[2]/len(y_train) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------테스트 데이터의 비율-----------\n",
      "중립 = 59.213%\n",
      "긍정 = 28.261%\n",
      "부정 = 12.526%\n"
     ]
    }
   ],
   "source": [
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'중립 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
    "print(f'긍정 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')\n",
    "print(f'부정 = {round(y_test.value_counts()[2]/len(y_test) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='klue/bert-base', vocab_size=32000, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "\n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
    "\n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "\n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3861/3861 [00:00<00:00, 3949.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 966/966 [00:00<00:00, 4009.93it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = convert_examples_to_features(X_test, y_test, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    2  4048  2063  2259 10735  2147  2227  2079  8660 27135 10735  2147\n",
      "  4401  4286  2205  2259  4946  2052  4169  2085   575  6233  4045 19521\n",
      "  1513  2062    18     3     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : [CLS] 보험사는 노르데아의 순이익에서 노르데아가 차지하는 비중이 상당할 것으로 예상하고 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "레이블 : 1\n"
     ]
    }
   ],
   "source": [
    "input_id = train_X[0][0]\n",
    "attention_mask = train_X[1][0]\n",
    "token_type_id = train_X[2][0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('어텐션 마스크 :',attention_mask)\n",
    "print('세그먼트 인코딩 :',token_type_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'COLAB_TPU_ADDR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TPU 작동을 위한 코드\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m resolver \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mcluster_resolver\u001b[38;5;241m.\u001b[39mTPUClusterResolver(tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrpc://\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOLAB_TPU_ADDR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      3\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental_connect_to_cluster(resolver)\n\u001b[0;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mtpu\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39minitialize_tpu_system(resolver)\n",
      "File \u001b[1;32m<frozen os>:714\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
     ]
    }
   ],
   "source": [
    "# TPU 작동을 위한 코드\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3, from_pt=True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001,\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    train_X, train_y, epochs=2, batch_size=32, validation_split=0.2,\n",
    "    callbacks = [early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_y, batch_size=1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
